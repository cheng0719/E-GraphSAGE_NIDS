{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fb9e1b2-1c5f-49e3-82b4-3bfe52cabad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_scatter\n",
    "import torch_sparse\n",
    "import torch_cluster\n",
    "import torch_spline_conv\n",
    "import torch_geometric\n",
    "from torch_geometric.utils import from_networkx, add_self_loops, degree\n",
    "from torch_geometric.nn import MessagePassing\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.loader import NeighborSampler\n",
    "import torch.nn as nn\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "# import dgl.function as fn\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import socket\n",
    "import struct\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d9ef09a-d405-43b8-971e-fe9e6a592c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack\n",
      "Benign                      7190742\n",
      "DDOS attack-HOIC             467052\n",
      "DoS attacks-Hulk             187046\n",
      "DDoS attacks-LOIC-HTTP       133048\n",
      "Bot                           62116\n",
      "Infilteration                 50089\n",
      "SSH-Bruteforce                41152\n",
      "DoS attacks-GoldenEye         12002\n",
      "FTP-BruteForce                11307\n",
      "DoS attacks-SlowHTTPTest       6063\n",
      "DoS attacks-Slowloris          4086\n",
      "Brute Force -Web                956\n",
      "DDOS attack-LOIC-UDP            883\n",
      "Brute Force -XSS                407\n",
      "SQL Injection                   198\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./Dataset/NF-CSE-CIC-IDS2018.csv')\n",
    "print(data['Attack'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "449a1af1-1d3d-4179-9628-7c2ec551ce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['PROTOCOL', 'L7_PROTO', 'TCP_FLAGS', 'CLIENT_TCP_FLAGS', 'SERVER_TCP_FLAGS', 'ICMP_TYPE', 'ICMP_IPV4_TYPE', \\\n",
    "                   'DNS_QUERY_ID', 'DNS_QUERY_TYPE', 'DNS_TTL_ANSWER', 'FTP_COMMAND_RET_CODE'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eb74f87-8df1-4c98-a849-e263e03a06f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "0.0    7190742\n",
      "1.0     976405\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.Label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a2c690c-86a4-49f7-aa9c-58f94529547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['IPV4_SRC_ADDR'] = data.IPV4_SRC_ADDR.apply(str)\n",
    "data['L4_SRC_PORT'] = data.L4_SRC_PORT.apply(int)\n",
    "data['L4_SRC_PORT'] = data.L4_SRC_PORT.apply(str)\n",
    "data['IPV4_DST_ADDR'] = data.IPV4_DST_ADDR.apply(str)\n",
    "data['L4_DST_PORT'] = data.L4_DST_PORT.apply(int)\n",
    "data['L4_DST_PORT'] = data.L4_DST_PORT.apply(str)\n",
    "data['IPV4_SRC_ADDR'] = data['IPV4_SRC_ADDR'] + ':' + data['L4_SRC_PORT']\n",
    "data['IPV4_DST_ADDR'] = data['IPV4_DST_ADDR'] + ':' + data['L4_DST_PORT']\n",
    "data.rename(columns={\"IPV4_SRC_ADDR\": \"saddr\"},inplace = True)\n",
    "data.rename(columns={\"IPV4_DST_ADDR\": \"daddr\"},inplace = True)\n",
    "data.drop(columns=['L4_SRC_PORT', 'L4_DST_PORT'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5651ef5b-0a9d-4641-aad7-5738092c46ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                          saddr               daddr  IN_BYTES  IN_PKTS  \\\n",
      "0            13.58.98.64:40894     172.31.69.25:22    3164.0     23.0   \n",
      "1        213.202.230.143:29622  172.31.66.103:3389    1919.0     14.0   \n",
      "2            172.31.66.5:65456       172.31.0.2:53     116.0      2.0   \n",
      "3           172.31.64.92:57918       172.31.0.2:53      70.0      1.0   \n",
      "4           18.219.32.43:63269     172.31.69.25:80     232.0      5.0   \n",
      "...                        ...                 ...       ...      ...   \n",
      "8167142     172.31.66.16:59566       172.31.0.2:53      75.0      1.0   \n",
      "8167143     172.31.68.26:61394       172.31.0.2:53      63.0      1.0   \n",
      "8167144    52.14.136.135:61501     172.31.69.25:80     232.0      5.0   \n",
      "8167145     172.31.69.24:60678  172.31.69.14:15002      44.0      1.0   \n",
      "8167146     172.31.65.86:53240    23.36.33.118:443     971.0      9.0   \n",
      "\n",
      "         OUT_BYTES  OUT_PKTS  FLOW_DURATION_MILLISECONDS  DURATION_IN  \\\n",
      "0           3765.0      21.0                         0.0          0.0   \n",
      "1           2031.0      11.0                         0.0          0.0   \n",
      "2            148.0       2.0                         0.0          0.0   \n",
      "3            130.0       1.0                         0.0          0.0   \n",
      "4           1136.0       4.0                   4294827.0        140.0   \n",
      "...            ...       ...                         ...          ...   \n",
      "8167142      203.0       1.0                         0.0          0.0   \n",
      "8167143      111.0       1.0                         0.0          0.0   \n",
      "8167144     1136.0       4.0                   4294936.0         31.0   \n",
      "8167145        0.0       0.0                         0.0          0.0   \n",
      "8167146     5478.0       9.0                         0.0          0.0   \n",
      "\n",
      "         DURATION_OUT  MIN_TTL  ...  DST_TO_SRC_AVG_THROUGHPUT  \\\n",
      "0                 0.0     63.0  ...                 30120000.0   \n",
      "1                 0.0    101.0  ...                 16248000.0   \n",
      "2                 0.0    128.0  ...                  1184000.0   \n",
      "3                 0.0      0.0  ...                  1040000.0   \n",
      "4                 0.0    127.0  ...                  9088000.0   \n",
      "...               ...      ...  ...                        ...   \n",
      "8167142           0.0    128.0  ...                  1624000.0   \n",
      "8167143           0.0      0.0  ...                   888000.0   \n",
      "8167144          15.0    127.0  ...                   568000.0   \n",
      "8167145           0.0      0.0  ...                        0.0   \n",
      "8167146           0.0    128.0  ...                 43824000.0   \n",
      "\n",
      "         NUM_PKTS_UP_TO_128_BYTES  NUM_PKTS_128_TO_256_BYTES  \\\n",
      "0                            33.0                        7.0   \n",
      "1                            17.0                        6.0   \n",
      "2                             4.0                        0.0   \n",
      "3                             1.0                        1.0   \n",
      "4                             8.0                        0.0   \n",
      "...                           ...                        ...   \n",
      "8167142                       2.0                        1.0   \n",
      "8167143                       2.0                        0.0   \n",
      "8167144                       8.0                        0.0   \n",
      "8167145                       1.0                        0.0   \n",
      "8167146                      11.0                        1.0   \n",
      "\n",
      "         NUM_PKTS_256_TO_512_BYTES  NUM_PKTS_512_TO_1024_BYTES  \\\n",
      "0                              1.0                         2.0   \n",
      "1                              0.0                         1.0   \n",
      "2                              0.0                         0.0   \n",
      "3                              0.0                         0.0   \n",
      "4                              0.0                         1.0   \n",
      "...                            ...                         ...   \n",
      "8167142                        0.0                         0.0   \n",
      "8167143                        0.0                         0.0   \n",
      "8167144                        0.0                         1.0   \n",
      "8167145                        0.0                         0.0   \n",
      "8167146                        2.0                         1.0   \n",
      "\n",
      "         NUM_PKTS_1024_TO_1514_BYTES  TCP_WIN_MAX_IN  TCP_WIN_MAX_OUT  Label  \\\n",
      "0                                1.0         26883.0          26847.0    1.0   \n",
      "1                                1.0          8192.0          64000.0    0.0   \n",
      "2                                0.0             0.0              0.0    0.0   \n",
      "3                                0.0             0.0              0.0    0.0   \n",
      "4                                0.0          8192.0          26883.0    1.0   \n",
      "...                              ...             ...              ...    ...   \n",
      "8167142                          0.0             0.0              0.0    0.0   \n",
      "8167143                          0.0             0.0              0.0    0.0   \n",
      "8167144                          0.0          8192.0          26883.0    1.0   \n",
      "8167145                          0.0          1024.0              0.0    0.0   \n",
      "8167146                          3.0          8192.0          29200.0    0.0   \n",
      "\n",
      "                         Attack  \n",
      "0                SSH-Bruteforce  \n",
      "1                        Benign  \n",
      "2                        Benign  \n",
      "3                        Benign  \n",
      "4        DDoS attacks-LOIC-HTTP  \n",
      "...                         ...  \n",
      "8167142                  Benign  \n",
      "8167143                  Benign  \n",
      "8167144  DDoS attacks-LOIC-HTTP  \n",
      "8167145                  Benign  \n",
      "8167146                  Benign  \n",
      "\n",
      "[8167147 rows x 32 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb7fb458-ca34-42ca-a8af-f8e1609aff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ground_truth = data[[\"saddr\", \"daddr\", \"Label\"]]\n",
    "class_ground_truth = data[[\"saddr\", \"daddr\", \"Attack\"]]\n",
    "# data = pd.get_dummies(data, columns = ['flgs_number','state_number', 'proto_number']) # One Hot Encoding for categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2d96115-31f9-48cb-b3e6-7853d2d253cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                          saddr               daddr  IN_BYTES  IN_PKTS  \\\n",
      "0            13.58.98.64:40894     172.31.69.25:22    3164.0     23.0   \n",
      "1        213.202.230.143:29622  172.31.66.103:3389    1919.0     14.0   \n",
      "2            172.31.66.5:65456       172.31.0.2:53     116.0      2.0   \n",
      "3           172.31.64.92:57918       172.31.0.2:53      70.0      1.0   \n",
      "4           18.219.32.43:63269     172.31.69.25:80     232.0      5.0   \n",
      "...                        ...                 ...       ...      ...   \n",
      "8167142     172.31.66.16:59566       172.31.0.2:53      75.0      1.0   \n",
      "8167143     172.31.68.26:61394       172.31.0.2:53      63.0      1.0   \n",
      "8167144    52.14.136.135:61501     172.31.69.25:80     232.0      5.0   \n",
      "8167145     172.31.69.24:60678  172.31.69.14:15002      44.0      1.0   \n",
      "8167146     172.31.65.86:53240    23.36.33.118:443     971.0      9.0   \n",
      "\n",
      "         OUT_BYTES  OUT_PKTS  FLOW_DURATION_MILLISECONDS  DURATION_IN  \\\n",
      "0           3765.0      21.0                         0.0          0.0   \n",
      "1           2031.0      11.0                         0.0          0.0   \n",
      "2            148.0       2.0                         0.0          0.0   \n",
      "3            130.0       1.0                         0.0          0.0   \n",
      "4           1136.0       4.0                   4294827.0        140.0   \n",
      "...            ...       ...                         ...          ...   \n",
      "8167142      203.0       1.0                         0.0          0.0   \n",
      "8167143      111.0       1.0                         0.0          0.0   \n",
      "8167144     1136.0       4.0                   4294936.0         31.0   \n",
      "8167145        0.0       0.0                         0.0          0.0   \n",
      "8167146     5478.0       9.0                         0.0          0.0   \n",
      "\n",
      "         DURATION_OUT  MIN_TTL  ...  DST_TO_SRC_AVG_THROUGHPUT  \\\n",
      "0                 0.0     63.0  ...                 30120000.0   \n",
      "1                 0.0    101.0  ...                 16248000.0   \n",
      "2                 0.0    128.0  ...                  1184000.0   \n",
      "3                 0.0      0.0  ...                  1040000.0   \n",
      "4                 0.0    127.0  ...                  9088000.0   \n",
      "...               ...      ...  ...                        ...   \n",
      "8167142           0.0    128.0  ...                  1624000.0   \n",
      "8167143           0.0      0.0  ...                   888000.0   \n",
      "8167144          15.0    127.0  ...                   568000.0   \n",
      "8167145           0.0      0.0  ...                        0.0   \n",
      "8167146           0.0    128.0  ...                 43824000.0   \n",
      "\n",
      "         NUM_PKTS_UP_TO_128_BYTES  NUM_PKTS_128_TO_256_BYTES  \\\n",
      "0                            33.0                        7.0   \n",
      "1                            17.0                        6.0   \n",
      "2                             4.0                        0.0   \n",
      "3                             1.0                        1.0   \n",
      "4                             8.0                        0.0   \n",
      "...                           ...                        ...   \n",
      "8167142                       2.0                        1.0   \n",
      "8167143                       2.0                        0.0   \n",
      "8167144                       8.0                        0.0   \n",
      "8167145                       1.0                        0.0   \n",
      "8167146                      11.0                        1.0   \n",
      "\n",
      "         NUM_PKTS_256_TO_512_BYTES  NUM_PKTS_512_TO_1024_BYTES  \\\n",
      "0                              1.0                         2.0   \n",
      "1                              0.0                         1.0   \n",
      "2                              0.0                         0.0   \n",
      "3                              0.0                         0.0   \n",
      "4                              0.0                         1.0   \n",
      "...                            ...                         ...   \n",
      "8167142                        0.0                         0.0   \n",
      "8167143                        0.0                         0.0   \n",
      "8167144                        0.0                         1.0   \n",
      "8167145                        0.0                         0.0   \n",
      "8167146                        2.0                         1.0   \n",
      "\n",
      "         NUM_PKTS_1024_TO_1514_BYTES  TCP_WIN_MAX_IN  TCP_WIN_MAX_OUT  Label  \\\n",
      "0                                1.0         26883.0          26847.0    1.0   \n",
      "1                                1.0          8192.0          64000.0    0.0   \n",
      "2                                0.0             0.0              0.0    0.0   \n",
      "3                                0.0             0.0              0.0    0.0   \n",
      "4                                0.0          8192.0          26883.0    1.0   \n",
      "...                              ...             ...              ...    ...   \n",
      "8167142                          0.0             0.0              0.0    0.0   \n",
      "8167143                          0.0             0.0              0.0    0.0   \n",
      "8167144                          0.0          8192.0          26883.0    1.0   \n",
      "8167145                          0.0          1024.0              0.0    0.0   \n",
      "8167146                          3.0          8192.0          29200.0    0.0   \n",
      "\n",
      "                         Attack  \n",
      "0                SSH-Bruteforce  \n",
      "1                        Benign  \n",
      "2                        Benign  \n",
      "3                        Benign  \n",
      "4        DDoS attacks-LOIC-HTTP  \n",
      "...                         ...  \n",
      "8167142                  Benign  \n",
      "8167143                  Benign  \n",
      "8167144  DDoS attacks-LOIC-HTTP  \n",
      "8167145                  Benign  \n",
      "8167146                  Benign  \n",
      "\n",
      "[8167147 rows x 32 columns]>\n"
     ]
    }
   ],
   "source": [
    "data = data.reset_index()\n",
    "data.replace([np.inf, -np.inf], np.nan,inplace = True)\n",
    "data.fillna(0,inplace = True)\n",
    "data.drop(columns=['index'],inplace=True)\n",
    "print(data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1df5c4c-70a2-4566-ae5e-ee3dcc6037a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpds/anaconda3/lib/python3.11/site-packages/pandas/core/nanops.py:1010: RuntimeWarning: overflow encountered in square\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       MAX_IP_PKT_LEN       IN_PKTS  SRC_TO_DST_AVG_THROUGHPUT      IN_BYTES  \\\n",
      "count    8.167147e+06  8.167147e+06               8.167147e+06  8.167147e+06   \n",
      "mean     5.642520e+02  2.292705e+01               4.750216e+06  1.785934e+03   \n",
      "std      5.388275e+02  1.073211e+03               1.055848e+07  6.932865e+04   \n",
      "min      2.800000e+01  1.000000e+00               0.000000e+00  2.800000e+01   \n",
      "25%      1.000000e+02  1.000000e+00               5.200000e+05  6.900000e+01   \n",
      "50%      1.910000e+02  4.000000e+00               9.920000e+05  1.800000e+02   \n",
      "75%      1.189000e+03  9.000000e+00               9.096000e+06  1.460000e+03   \n",
      "max      6.521200e+04  2.430310e+05               3.520027e+09  5.760577e+07   \n",
      "\n",
      "       NUM_PKTS_1024_TO_1514_BYTES  SHORTEST_FLOW_PKT     OUT_BYTES  \\\n",
      "count                 8.167147e+06       8.167147e+06  8.167147e+06   \n",
      "mean                  4.202104e+00       5.359188e+01  6.907992e+03   \n",
      "std                   3.239484e+02       3.617786e+01  4.863405e+05   \n",
      "min                   0.000000e+00       2.800000e+01  0.000000e+00   \n",
      "25%                   0.000000e+00       4.000000e+01  1.170000e+02   \n",
      "50%                   0.000000e+00       4.000000e+01  3.220000e+02   \n",
      "75%                   1.000000e+00       6.600000e+01  1.873000e+03   \n",
      "max                   1.761450e+05       1.500000e+03  2.643994e+08   \n",
      "\n",
      "            MAX_TTL  DURATION_OUT  FLOW_DURATION_MILLISECONDS  ...  \\\n",
      "count  8.167147e+06  8.167147e+06                8.167147e+06  ...   \n",
      "mean   7.160106e+01  1.132302e+01                5.746851e+05  ...   \n",
      "std    5.701637e+01  7.673829e+01                1.462152e+06  ...   \n",
      "min    0.000000e+00  0.000000e+00                0.000000e+00  ...   \n",
      "25%    0.000000e+00  0.000000e+00                0.000000e+00  ...   \n",
      "50%    1.010000e+02  0.000000e+00                0.000000e+00  ...   \n",
      "75%    1.280000e+02  0.000000e+00                0.000000e+00  ...   \n",
      "max    2.550000e+02  4.721800e+04                4.294967e+06  ...   \n",
      "\n",
      "       LONGEST_FLOW_PKT  NUM_PKTS_128_TO_256_BYTES  SRC_TO_DST_SECOND_BYTES  \\\n",
      "count      8.167147e+06               8.167147e+06             8.167147e+06   \n",
      "mean       5.642520e+02               1.341835e+00            7.205503e+294   \n",
      "std        5.388275e+02               6.738311e+00                      inf   \n",
      "min        2.800000e+01               0.000000e+00             0.000000e+00   \n",
      "25%        1.000000e+02               0.000000e+00             7.000000e+01   \n",
      "50%        1.910000e+02               1.000000e+00             2.080000e+02   \n",
      "75%        1.189000e+03               2.000000e+00             1.460000e+03   \n",
      "max        6.521200e+04               6.514000e+03            5.754038e+301   \n",
      "\n",
      "       RETRANSMITTED_IN_PKTS  DST_TO_SRC_AVG_THROUGHPUT       MIN_TTL  \\\n",
      "count           8.167147e+06               8.167147e+06  8.167147e+06   \n",
      "mean            5.382254e-01               1.387480e+07  7.149608e+01   \n",
      "std             2.960829e+00               9.465818e+07  5.690907e+01   \n",
      "min             0.000000e+00               0.000000e+00  0.000000e+00   \n",
      "25%             0.000000e+00               7.600000e+05  0.000000e+00   \n",
      "50%             0.000000e+00               1.432000e+06  1.010000e+02   \n",
      "75%             0.000000e+00               1.376800e+07  1.280000e+02   \n",
      "max             1.182000e+03               4.294232e+09  2.550000e+02   \n",
      "\n",
      "       NUM_PKTS_UP_TO_128_BYTES  TCP_WIN_MAX_OUT  TCP_WIN_MAX_IN  \\\n",
      "count              8.167147e+06     8.167147e+06    8.167147e+06   \n",
      "mean               2.585446e+01     2.096106e+04    1.150025e+04   \n",
      "std                1.073965e+03     2.503588e+04    1.908135e+04   \n",
      "min                0.000000e+00     0.000000e+00    0.000000e+00   \n",
      "25%                2.000000e+00     0.000000e+00    0.000000e+00   \n",
      "50%                6.000000e+00     8.192000e+03    8.192000e+03   \n",
      "75%                1.200000e+01     2.920000e+04    8.192000e+03   \n",
      "max                2.430310e+05     6.553500e+04    6.553500e+04   \n",
      "\n",
      "       RETRANSMITTED_OUT_PKTS  \n",
      "count            8.167147e+06  \n",
      "mean             1.137386e-01  \n",
      "std              2.742373e+00  \n",
      "min              0.000000e+00  \n",
      "25%              0.000000e+00  \n",
      "50%              0.000000e+00  \n",
      "75%              0.000000e+00  \n",
      "max              2.439000e+03  \n",
      "\n",
      "[8 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "cols_to_norm = list(set(list(data.iloc[:, 2:].columns ))  - set(list(['Label']))  - set(list(['Attack'])) )\n",
    "print(data[cols_to_norm].describe()) # Check if there's any too large value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37256006-abc1-44aa-8e74-46d05dc6ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[cols_to_norm] = data[cols_to_norm].clip(lower=-1e9, upper=1e9)\n",
    "data[cols_to_norm] = scaler.fit_transform(data[cols_to_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d35f4cdd-2716-431f-af50-b34cc3d2d535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2450144\n",
      "1143400\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     data, label_ground_truth, test_size=0.4, random_state=42, stratify=label_ground_truth.Label)\n",
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ab790ad-fb42-4eba-9d29-cef8fd5bec8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "0.0    1006703\n",
      "1.0     136697\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_test.Label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f83bd73-531f-42a0-9f73-e1fd98dce1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['h'] = X_train[ cols_to_norm ].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98f829f-ecae-4af3-bf24-ad50167a67a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "attack_labels = le.fit_transform(X_train['Attack'])\n",
    "class_map = le.classes_\n",
    "print(class_map)\n",
    "print(\"Attack label mapping:\", dict(zip(class_map, range(len(class_map)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8f9cdb-1316-461a-a927-8d67d90d6144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert NetworkX graph to PyG graph\n",
    "G_nx = nx.from_pandas_edgelist(X_train, \"saddr\", \"daddr\", ['h', 'Label'], create_using=nx.MultiDiGraph())\n",
    "G_pyg = from_networkx(G_nx)\n",
    "\n",
    "num_nodes = G_pyg.num_nodes\n",
    "num_edges = G_pyg.num_edges\n",
    "\n",
    "G_pyg.x = th.ones(num_nodes, len(X_train['h'].iloc[0])) \n",
    "\n",
    "edge_attr_list = []\n",
    "edge_label_list = []\n",
    "\n",
    "for u, v, key, data in G_nx.edges(keys=True, data=True):\n",
    "    edge_attr_list.append(data['h']) \n",
    "    edge_label_list.append(data['Label']) \n",
    "\n",
    "G_pyg.edge_attr = th.tensor(edge_attr_list, dtype=th.float32)\n",
    "G_pyg.edge_label = th.tensor(edge_label_list, dtype=th.long)\n",
    "G_pyg.edge_class = th.tensor(attack_labels, dtype=th.long)\n",
    "\n",
    "print(\"Number of edges in G_pyg:\", G_pyg.num_edges)\n",
    "print(\"Number of node in G_pyg:\", G_pyg.num_nodes)\n",
    "print(\"Shape of node in G_pyg:\", G_pyg.x.shape)\n",
    "print(\"Shape of edge attr in G_pyg:\", G_pyg.edge_attr.shape)\n",
    "print(\"Shape of edge label in G_pyg:\", G_pyg.edge_label.shape)\n",
    "print(\"Shape of edge class in G_pyg:\", G_pyg.edge_class.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41795339-6036-468f-9b9d-2bb68d78ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EGraphSAGEConv(MessagePassing):\n",
    "    def __init__(self, node_in_channels, edge_in_channels, out_channels):\n",
    "        super(EGraphSAGEConv, self).__init__(aggr='mean')  # mean aggregation\n",
    "        self.lin_node = nn.Linear(node_in_channels, out_channels)\n",
    "        self.lin_edge = nn.Linear(edge_in_channels, out_channels)\n",
    "        self.lin_update = nn.Linear(node_in_channels + out_channels, out_channels) # out_channels * 2\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # x: Node features, edge_attr: Edge features, edge_index: Connectivity\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        if edge_attr is not None:\n",
    "            if edge_attr.size(0) != edge_index.size(1):\n",
    "                loop_attr = th.zeros((edge_index.size(1) - edge_attr.size(0), edge_attr.size(1))).to(edge_attr.device)\n",
    "                edge_attr = th.cat([edge_attr, loop_attr], dim=0)\n",
    "        else:\n",
    "            print(\"edge_attr is unexist\")\n",
    "        \n",
    "        # Propagate and aggregate neighbor information\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        # x_j represents the adjacent nodes of x\n",
    "        # Compute messages by combining node and edge features\n",
    "        return self.lin_node(x_j) + self.lin_edge(edge_attr)\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        # Update node features after message passing\n",
    "        return self.lin_update(th.cat([x, aggr_out], dim=1))\n",
    "\n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(MLPPredictor, self).__init__()\n",
    "        self.lin = nn.Linear(in_channels * 2, out_channels)\n",
    "\n",
    "    def forward(self, data, z):\n",
    "        row, col = data.edge_index\n",
    "        # Concatenate the features of source and target nodes for each edge\n",
    "        edge_feat = th.cat([z[row], z[col]], dim=1)\n",
    "        return self.lin(edge_feat)\n",
    "\n",
    "class EGraphSAGE(nn.Module):\n",
    "    def __init__(self, node_in_channels, edge_in_channels, hidden_channels, out_channels):\n",
    "        super(EGraphSAGE, self).__init__()\n",
    "        self.conv1 = EGraphSAGEConv(node_in_channels, edge_in_channels, hidden_channels)\n",
    "        self.conv2 = EGraphSAGEConv(hidden_channels, edge_in_channels, hidden_channels)\n",
    "        self.mlp_predictor = MLPPredictor(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        return self.mlp_predictor(data, x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bca25fef-29d9-40cf-8910-16b24d530693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = th.device(\"cuda:0\" if th.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cccdc850-b98d-4836-b82b-67aa4b9e1e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "th.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89157faf-e24b-49d6-9c90-6f71dae515b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EGraphSAGE(node_in_channels=G_pyg.num_node_features, \n",
    "                   edge_in_channels=G_pyg.num_edge_features,\n",
    "                   hidden_channels=128, \n",
    "                   out_channels=2).to(device)\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "labels = G_pyg.edge_label.cpu().numpy()\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                  classes=np.unique(labels),\n",
    "                                                  y=labels)\n",
    "\n",
    "class_weights = th.FloatTensor(class_weights).cuda()\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights)\n",
    "optimizer = th.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385d37f0-713b-4abc-8d7a-3e768ae9a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import subgraph\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def compute_accuracy(pred, labels):\n",
    "    return (pred.argmax(1) == labels).float().mean().item()\n",
    "\n",
    "G_pyg.edge_label = G_pyg.edge_label.to(device)\n",
    "G_pyg.edge_attr = G_pyg.edge_attr.to(device)\n",
    "\n",
    "def generate_edge_based_batches_with_node_expansion(graph, batch_size, min_nodes):\n",
    "    num_edges = graph.edge_index.size(1)  # Get total number of edges\n",
    "    edge_indices = th.arange(num_edges)   # Create list of edge indices\n",
    "    num_edges_processed = 0\n",
    "    \n",
    "    while num_edges_processed < num_edges:\n",
    "        # Select a batch of edges\n",
    "        batch_edge_indices = edge_indices[num_edges_processed : min(num_edges_processed + batch_size, num_edges)]\n",
    "        edge_index = graph.edge_index[:, batch_edge_indices]\n",
    "        \n",
    "        # Update the number of edges processed\n",
    "        num_edges_processed += batch_size\n",
    "        \n",
    "        # Get the unique nodes associated with these edges\n",
    "        batch_nodes = th.cat([edge_index[0], edge_index[1]]).unique()\n",
    "\n",
    "        # Check if the batch has enough unique nodes\n",
    "        while batch_nodes.size(0) < min_nodes:\n",
    "            # Sample additional neighboring nodes to ensure diversity\n",
    "            additional_edges = int(batch_size / 8)  # Ensure additional_edges is an integer\n",
    "            batch_edge_indices = th.cat([batch_edge_indices, edge_indices[num_edges_processed : min(num_edges_processed + additional_edges, num_edges)]])\n",
    "            edge_index = graph.edge_index[:, batch_edge_indices]\n",
    "            batch_nodes = th.cat([edge_index[0], edge_index[1]]).unique()\n",
    "            num_edges_processed += additional_edges\n",
    "\n",
    "            # Avoid potential infinite loops by breaking if no more edges can be added\n",
    "            if num_edges_processed >= num_edges:\n",
    "                break\n",
    "\n",
    "        # Create subgraph from the selected nodes and edges\n",
    "        edge_index, _, edge_mask = subgraph(batch_nodes, graph.edge_index, relabel_nodes=True, return_edge_mask=True)\n",
    "\n",
    "        # Use edge_mask to select edge attributes and labels\n",
    "        edge_attr = graph.edge_attr[edge_mask]\n",
    "        edge_label = graph.edge_label[edge_mask]\n",
    "\n",
    "        yield batch_nodes, edge_index, edge_attr, edge_label\n",
    "\n",
    "batch_size = 64\n",
    "for epoch in range(5):\n",
    "    print(f'epoch : {epoch}')\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    try:\n",
    "        for batch_idx, (batch_nodes, edge_index, edge_attr, edge_label) in enumerate(generate_edge_based_batches_with_node_expansion(G_pyg, batch_size, 20)):\n",
    "            # print(f\"Processing epoch {epoch}, batch {batch_idx} with {batch_nodes.size(0)} nodes and {edge_index.size(1)} edges\")\n",
    "            batch = Data(x=G_pyg.x[batch_nodes], edge_index=edge_index, edge_attr=edge_attr, edge_label=edge_label)\n",
    "            \n",
    "            if batch.edge_index.size(1) == 0 or batch.edge_label.size(0) == 0:\n",
    "                print(f\"Warning: Empty batch at batch {batch_idx}\")\n",
    "                continue\n",
    "                \n",
    "            if batch is None or batch.num_nodes == 0:\n",
    "                print(f\"Warning: Empty batch at Batch {batch_idx}\")\n",
    "                continue \n",
    "    \n",
    "            if th.isnan(batch.x).any() or th.isinf(batch.x).any() or th.isnan(batch.edge_attr).any() or th.isinf(batch.edge_attr).any():\n",
    "                print(f\"Warning: batch x and edge_attr contains NaN or Inf at Batch {batch_idx}\")\n",
    "                continue \n",
    "                \n",
    "            try:\n",
    "                batch = batch.to(device)\n",
    "            except Exception as batch_error:\n",
    "                print(f\"Error moving batch to device at Batch {batch_idx}: {batch_error}\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                out = model(batch)\n",
    "    \n",
    "                if th.isnan(out).any() or th.isinf(out).any():\n",
    "                    print(f\"Warning: out contains NaN or Inf at Batch {batch_idx}\")\n",
    "                    continue \n",
    "                all_preds.append(out)\n",
    "                all_labels.append(batch.edge_label)\n",
    "    \n",
    "                loss = criterion(out, batch.edge_label)\n",
    "                if th.isnan(loss):\n",
    "                    print(f\"loss: {loss}\")\n",
    "                    print(f\"out: {out}\")\n",
    "                    print(f\"edge_labels: {batch.edge_label}\")\n",
    "                    \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            except Exception as forward_error:\n",
    "                print(f\"Error during forward/backward pass at Epoch {epoch}, Batch {batch_idx}: {forward_error}\")\n",
    "                continue\n",
    "        \n",
    "        all_preds = th.cat(all_preds)\n",
    "        all_labels = th.cat(all_labels)\n",
    "        \n",
    "        epoch_accuracy = compute_accuracy(all_preds, all_labels)\n",
    "        print(f'Epoch {epoch}, Loss: {loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n",
    "        print(all_labels.shape)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred at epoch {epoch}, batch {batch_idx}: {str(e)}\")\n",
    "print(\"Training is over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac63f9fc-02a2-4e16-94c6-bef7bf80ecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "th.save(model.state_dict(), \"./Weights/GNN_model_weights_CICIDS2018_subset_2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9742c0d1-0e23-4c5f-bcfc-c72a3f92f558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Benign' 'Bot' 'Brute Force -Web' 'Brute Force -XSS' 'DDOS attack-HOIC'\n",
      " 'DDOS attack-LOIC-UDP' 'DDoS attacks-LOIC-HTTP' 'DoS attacks-GoldenEye'\n",
      " 'DoS attacks-Hulk' 'DoS attacks-SlowHTTPTest' 'DoS attacks-Slowloris'\n",
      " 'FTP-BruteForce' 'Infilteration' 'SQL Injection' 'SSH-Bruteforce']\n",
      "Attack label mapping: {'Benign': 0, 'Bot': 1, 'Brute Force -Web': 2, 'Brute Force -XSS': 3, 'DDOS attack-HOIC': 4, 'DDOS attack-LOIC-UDP': 5, 'DDoS attacks-LOIC-HTTP': 6, 'DoS attacks-GoldenEye': 7, 'DoS attacks-Hulk': 8, 'DoS attacks-SlowHTTPTest': 9, 'DoS attacks-Slowloris': 10, 'FTP-BruteForce': 11, 'Infilteration': 12, 'SQL Injection': 13, 'SSH-Bruteforce': 14}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "test_le = LabelEncoder()\n",
    "X_test['Attack'] = test_le.fit_transform(X_test['Attack'])\n",
    "test_class_map = test_le.classes_\n",
    "print(test_class_map)\n",
    "print(\"Attack label mapping:\", dict(zip(test_class_map, range(len(test_class_map)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ab8db72-643a-476a-8c99-5c711869c1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges in G_pyg_test: 1143400\n",
      "Number of node in G_pyg_test: 1080734\n",
      "Shape of node in G_pyg_test: torch.Size([1080734, 28])\n",
      "Shape of edge attr in G_pyg_test: torch.Size([1143400, 28])\n",
      "Shape of edge label in G_pyg_test: torch.Size([1143400])\n",
      "Shape of edge class in G_pyg_test: torch.Size([1143400])\n"
     ]
    }
   ],
   "source": [
    "X_test['h'] = X_test[ cols_to_norm ].values.tolist()\n",
    "\n",
    "G_nx_test = nx.from_pandas_edgelist(X_test, \"saddr\", \"daddr\", ['h', 'Label', 'Attack'], create_using=nx.MultiDiGraph())\n",
    "\n",
    "G_pyg_test = from_networkx(G_nx_test)\n",
    "\n",
    "test_num_nodes = G_pyg_test.num_nodes\n",
    "test_num_edges = G_pyg_test.num_edges\n",
    "\n",
    "G_pyg_test.x = th.ones(test_num_nodes, len(X_test['h'].iloc[0]))\n",
    "\n",
    "test_edge_attr_list = []\n",
    "test_edge_label_list = []\n",
    "test_edge_class_list = []\n",
    "\n",
    "for u, v, key, data in G_nx_test.edges(keys=True, data=True):\n",
    "    test_edge_attr_list.append(data['h']) \n",
    "    test_edge_label_list.append(data['Label']) \n",
    "    test_edge_class_list.append(data['Attack'])\n",
    "\n",
    "G_pyg_test.edge_attr = th.tensor(test_edge_attr_list, dtype=th.float32)\n",
    "G_pyg_test.edge_label = th.tensor(test_edge_label_list, dtype=th.long)\n",
    "G_pyg_test.edge_class = th.tensor(test_edge_class_list, dtype=th.long)\n",
    "\n",
    "print(\"Number of edges in G_pyg_test:\", G_pyg_test.num_edges)\n",
    "print(\"Number of node in G_pyg_test:\", G_pyg_test.num_nodes)\n",
    "print(\"Shape of node in G_pyg_test:\", G_pyg_test.x.shape)\n",
    "print(\"Shape of edge attr in G_pyg_test:\", G_pyg_test.edge_attr.shape)\n",
    "print(\"Shape of edge label in G_pyg_test:\", G_pyg_test.edge_label.shape)\n",
    "print(\"Shape of edge class in G_pyg_test:\", G_pyg_test.edge_class.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "857f271a-612b-4cd6-a85a-e4236dec9d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference start\n",
      "inference done\n",
      "torch.Size([1146184, 2])\n",
      "torch.Size([1146184])\n",
      "torch.Size([1146184])\n",
      "Test Accuracy: 0.5270\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import subgraph\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def compute_accuracy(pred, labels):\n",
    "    return (pred.argmax(1) == labels).float().mean().item()\n",
    "\n",
    "new_model_2 = EGraphSAGE(node_in_channels=G_pyg_test.num_node_features, \n",
    "                       edge_in_channels=G_pyg_test.num_edge_features,\n",
    "                       hidden_channels=128, \n",
    "                       out_channels=2).to(device)\n",
    "\n",
    "new_model_2.load_state_dict(th.load(\"./Weights/GNN_model_weights_CICIDS2018_subset_2.pth\", weights_only=True))\n",
    "\n",
    "def generate_edge_based_batches_with_node_expansion(graph, batch_size, min_nodes):\n",
    "    num_edges = graph.edge_index.size(1) \n",
    "    edge_indices = th.arange(num_edges)  \n",
    "    num_edges_processed = 0\n",
    "    \n",
    "    while num_edges_processed < num_edges:\n",
    "        # Select a batch of edges\n",
    "        batch_edge_indices = edge_indices[num_edges_processed : min(num_edges_processed + batch_size, num_edges)]\n",
    "        edge_index = graph.edge_index[:, batch_edge_indices]\n",
    "        \n",
    "        # Update the number of edges processed\n",
    "        num_edges_processed += batch_size\n",
    "        \n",
    "        # Get the unique nodes associated with these edges\n",
    "        batch_nodes = th.cat([edge_index[0], edge_index[1]]).unique()\n",
    "\n",
    "        # Check if the batch has enough unique nodes\n",
    "        while batch_nodes.size(0) < min_nodes:\n",
    "            # Sample additional neighboring nodes to ensure diversity\n",
    "            additional_edges = int(batch_size / 8)  # Ensure additional_edges is an integer\n",
    "            batch_edge_indices = th.cat([batch_edge_indices, edge_indices[num_edges_processed : min(num_edges_processed + additional_edges, num_edges)]])\n",
    "            edge_index = graph.edge_index[:, batch_edge_indices]\n",
    "            batch_nodes = th.cat([edge_index[0], edge_index[1]]).unique()\n",
    "            num_edges_processed += additional_edges\n",
    "\n",
    "            # Avoid potential infinite loops by breaking if no more edges can be added\n",
    "            if num_edges_processed >= num_edges:\n",
    "                break\n",
    "\n",
    "        # Create subgraph from the selected nodes and edges\n",
    "        edge_index, _, edge_mask = subgraph(batch_nodes, graph.edge_index, relabel_nodes=True, return_edge_mask=True)\n",
    "\n",
    "        # Use edge_mask to select edge attributes and labels\n",
    "        edge_attr = graph.edge_attr[edge_mask]\n",
    "        edge_label = graph.edge_label[edge_mask]\n",
    "        edge_class = graph.edge_class[edge_mask]\n",
    "\n",
    "        yield batch_nodes, edge_index, edge_attr, edge_label, edge_class\n",
    "\n",
    "\n",
    "new_model_2.eval()\n",
    "\n",
    "all_test_preds = []\n",
    "all_test_labels = []\n",
    "all_test_classes = []\n",
    "attack_class_performance = {attack_type: {'correct': 0, 'incorrect': 0} for attack_type in test_class_map}\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "print(\"inference start\")\n",
    "with th.no_grad():\n",
    "    for batch_idx, (batch_nodes, edge_index, edge_attr, edge_label, edge_class) in enumerate(generate_edge_based_batches_with_node_expansion(G_pyg_test, batch_size, 20)):\n",
    "        # print(f\"Processing batch {batch_idx} with {batch_nodes.size(0)} nodes and {edge_index.size(1)} edges\")\n",
    "        batch = Data(x=G_pyg_test.x[batch_nodes], edge_index=edge_index, edge_attr=edge_attr, edge_label=edge_label)\n",
    "        \n",
    "        if batch.edge_index.size(1) == 0 or batch.edge_label.size(0) == 0:\n",
    "            print(f\"Warning: Empty batch at batch {batch_idx}\")\n",
    "            continue\n",
    "            \n",
    "        if batch is None or batch.num_nodes == 0:\n",
    "            print(f\"Warning: Empty batch at Batch {batch_idx}\")\n",
    "            continue\n",
    "\n",
    "        if th.isnan(batch.x).any() or th.isinf(batch.x).any() or th.isnan(batch.edge_attr).any() or th.isinf(batch.edge_attr).any():\n",
    "            print(f\"Warning: batch x and edge_attr contains NaN or Inf at Batch {batch_idx}\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            batch = batch.to(device)\n",
    "        except Exception as batch_error:\n",
    "            print(f\"Error moving batch to device at Batch {batch_idx}: {batch_error}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            out = new_model_2(batch)\n",
    "\n",
    "            if th.isnan(out).any() or th.isinf(out).any():\n",
    "                print(f\"Warning: out contains NaN or Inf at Batch {batch_idx}\")\n",
    "                continue \n",
    "            \n",
    "            all_test_preds.append(out)\n",
    "            all_test_labels.append(edge_label)\n",
    "            all_test_classes.append(edge_class)\n",
    "\n",
    "            pred = out.argmax(dim=1) \n",
    "\n",
    "            for i in range(len(pred)):\n",
    "                true_label = edge_label[i].item()\n",
    "                predicted_label = pred[i].item()\n",
    "                attack_type = test_le.inverse_transform([edge_class[i].item()])[0] \n",
    "\n",
    "                if true_label == 0 and attack_type != 'Benign':\n",
    "                    print('this sample is Benign but label is wrong')\n",
    "                \n",
    "                if true_label == predicted_label:\n",
    "                    attack_class_performance[attack_type]['correct'] += 1\n",
    "                else:\n",
    "                    attack_class_performance[attack_type]['incorrect'] += 1\n",
    "        except Exception as forward_error:\n",
    "            print(f\"Error during forward/backward pass at Batch {batch_idx}: {forward_error}\")\n",
    "            continue\n",
    "\n",
    "print(\"inference done\")\n",
    "all_test_preds = th.cat(all_test_preds).to(device)\n",
    "all_test_labels = th.cat(all_test_labels).to(device)\n",
    "all_test_classes = th.cat(all_test_classes).to(device)\n",
    "\n",
    "test_accuracy = compute_accuracy(all_test_preds, all_test_labels)\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f6bf70a-3dbc-48d7-9df0-5ff66e99ac38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives (TP): 5623\n",
      "False Positives (FP): 409411\n",
      "True Negatives (TN): 598395\n",
      "False Negatives (FN): 132755\n",
      "Accuracy: 0.5270\n",
      "Precision: 0.0135\n",
      "Recall: 0.0406\n",
      "F1 Score: 0.0203\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred_labels = all_test_preds.argmax(dim=1)\n",
    "\n",
    "pred_labels = pred_labels.cpu()\n",
    "all_test_labels = all_test_labels.cpu()\n",
    "\n",
    "cm = confusion_matrix(all_test_labels, pred_labels)\n",
    "\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "print(f'True Positives (TP): {TP}')\n",
    "print(f'False Positives (FP): {FP}')\n",
    "print(f'True Negatives (TN): {TN}')\n",
    "print(f'False Negatives (FN): {FN}')\n",
    "\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1_score:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1df046bd-b50b-481c-826d-2f4ce4569f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack Type: Benign, Accuracy: 0.5938, Total Samples: 1007806, Correct Samples: 598395, Incorrect Samples: 409411\n",
      "Attack Type: Bot, Accuracy: 0.0002, Total Samples: 8772, Correct Samples: 2, Incorrect Samples: 8770\n",
      "Attack Type: Brute Force -Web, Accuracy: 0.0000, Total Samples: 149, Correct Samples: 0, Incorrect Samples: 149\n",
      "Attack Type: Brute Force -XSS, Accuracy: 0.0000, Total Samples: 51, Correct Samples: 0, Incorrect Samples: 51\n",
      "Attack Type: DDOS attack-HOIC, Accuracy: 0.0000, Total Samples: 65972, Correct Samples: 1, Incorrect Samples: 65971\n",
      "Attack Type: DDOS attack-LOIC-UDP, Accuracy: 0.0000, Total Samples: 135, Correct Samples: 0, Incorrect Samples: 135\n",
      "Attack Type: DDoS attacks-LOIC-HTTP, Accuracy: 0.1121, Total Samples: 18991, Correct Samples: 2129, Incorrect Samples: 16862\n",
      "Attack Type: DoS attacks-GoldenEye, Accuracy: 0.0369, Total Samples: 1706, Correct Samples: 63, Incorrect Samples: 1643\n",
      "Attack Type: DoS attacks-Hulk, Accuracy: 0.0110, Total Samples: 26815, Correct Samples: 295, Incorrect Samples: 26520\n",
      "Attack Type: DoS attacks-SlowHTTPTest, Accuracy: 0.0000, Total Samples: 848, Correct Samples: 0, Incorrect Samples: 848\n",
      "Attack Type: DoS attacks-Slowloris, Accuracy: 0.3936, Total Samples: 592, Correct Samples: 233, Incorrect Samples: 359\n",
      "Attack Type: FTP-BruteForce, Accuracy: 0.0000, Total Samples: 1574, Correct Samples: 0, Incorrect Samples: 1574\n",
      "Attack Type: Infilteration, Accuracy: 0.4123, Total Samples: 7003, Correct Samples: 2887, Incorrect Samples: 4116\n",
      "Attack Type: SQL Injection, Accuracy: 0.0000, Total Samples: 24, Correct Samples: 0, Incorrect Samples: 24\n",
      "Attack Type: SSH-Bruteforce, Accuracy: 0.0023, Total Samples: 5746, Correct Samples: 13, Incorrect Samples: 5733\n",
      "138378\n"
     ]
    }
   ],
   "source": [
    "for attack_type, performance in attack_class_performance.items():\n",
    "    total_samples = performance['correct'] + performance['incorrect']\n",
    "    if attack_type != 'Benign':\n",
    "        sum += total_samples\n",
    "    accuracy = performance['correct'] / total_samples if total_samples > 0 else 0\n",
    "    print(f\"Attack Type: {attack_type}, Accuracy: {accuracy:.4f}, Total Samples: {total_samples}, Correct Samples: {performance['correct']}, Incorrect Samples: {performance['incorrect']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001d9b00-3518-49c9-bac2-60551a6d12ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
